{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python373jvsc74a57bd09164a3399a70d355c381b62813f30880ed90ca5a6f321bf0d85375640bda7ee5",
   "display_name": "Python 3.7.3 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "9164a3399a70d355c381b62813f30880ed90ca5a6f321bf0d85375640bda7ee5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os \n",
    "import cv2\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, Conv2D, Dense, Flatten, MaxPooling2D, TimeDistributed, Reshape\n",
    "from tensorflow.keras.models import Sequential\n",
    "import time\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from random import shuffle\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.0001\n",
    "BATCH_SIZE = 64\n",
    "MOMENTUM = 0.9\n",
    "IMG_SIZE = 224\n",
    "EPOCHS = 5\n",
    "\n",
    "TRAIN_DIR = './Peliculas/Data/train/'\n",
    "TEST_DIR = './Peliculas/Data/valid/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 4195/4195 [00:20<00:00, 207.71it/s]\n",
      "100%|██████████| 4410/4410 [00:18<00:00, 243.31it/s]\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DATA = []\n",
    "for folder in os.listdir(TRAIN_DIR):\n",
    "    for files in tqdm(os.listdir(os.path.join(TRAIN_DIR, folder))):\n",
    "        path = os.path.join(os.path.join(TRAIN_DIR, folder), files)\n",
    "        image = cv2.resize(cv2.imread(path), (IMG_SIZE, IMG_SIZE))\n",
    "        if folder == 'fight':\n",
    "            TRAIN_DATA.append([np.array(image), [1, 0]])\n",
    "        elif folder == 'nofight':\n",
    "            TRAIN_DATA.append([np.array(image), [0, 1]])\n",
    "\n",
    "shuffle(TRAIN_DATA)\n",
    "np.save('movie_training_data.npy', TRAIN_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 496/496 [00:02<00:00, 219.26it/s]\n",
      "100%|██████████| 539/539 [00:01<00:00, 274.18it/s]\n"
     ]
    }
   ],
   "source": [
    "TEST_DATA = []\n",
    "for folder in os.listdir(TEST_DIR):\n",
    "    for files in tqdm(os.listdir(os.path.join(TEST_DIR, folder))):\n",
    "        path = os.path.join(os.path.join(TEST_DIR, folder), files)\n",
    "        image = cv2.resize(cv2.imread(path), (IMG_SIZE, IMG_SIZE))\n",
    "        if folder == 'fight':\n",
    "            TEST_DATA.append([np.array(image), [1, 0]])\n",
    "        elif folder == 'nofight':\n",
    "            TEST_DATA.append([np.array(image), [0, 1]])\n",
    "\n",
    "shuffle(TEST_DATA)\n",
    "np.save('movie_testing_data.npy', TEST_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 4195/4195 [00:20<00:00, 202.91it/s]\n",
      "100%|██████████| 4410/4410 [00:17<00:00, 252.90it/s]\n",
      "100%|██████████| 496/496 [00:02<00:00, 208.98it/s]\n",
      "100%|██████████| 539/539 [00:02<00:00, 260.82it/s]\n",
      "C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\numpy\\core\\_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    }
   ],
   "source": [
    "DATA_SET = []\n",
    "for folders in os.listdir('./Peliculas/Data/'):\n",
    "    for folder in os.listdir('./Peliculas/Data/'+str(folders)):\n",
    "        folder_path = './Peliculas/Data/' + folders\n",
    "        for files in tqdm(os.listdir(os.path.join(folder_path, folder))):\n",
    "            path = os.path.join(os.path.join(folder_path, folder), files)\n",
    "            image = cv2.resize(cv2.imread(path), (IMG_SIZE, IMG_SIZE))\n",
    "            if folder == 'fight':\n",
    "                DATA_SET.append([np.array(image), [1, 0]])\n",
    "            elif folder == 'nofight':\n",
    "                DATA_SET.append([np.array(image), [0, 1]])\n",
    "\n",
    "shuffle(DATA_SET)\n",
    "np.save('movie_data.npy', DATA_SET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_4\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninception_v3 (Functional)    (None, 5, 5, 2048)        21802784  \n_________________________________________________________________\nglobal_average_pooling2d (Gl (None, 2048)              0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 2)                 4098      \n=================================================================\nTotal params: 21,806,882\nTrainable params: 4,098\nNon-trainable params: 21,802,784\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.applications.InceptionV3(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    ")\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "add_model = Sequential()\n",
    "add_model.add(base_model)\n",
    "add_model.add(GlobalAveragePooling2D())\n",
    "add_model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model = add_model\n",
    "model.compile(loss='categorical_crossentropy', optimizer = optimizers.SGD(lr=LR, momentum = 0.9), metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5\n",
      "136/136 [==============================] - 25s 183ms/step - loss: 0.0161 - accuracy: 0.9961 - val_loss: 0.0398 - val_accuracy: 0.9938\n",
      "Epoch 2/5\n",
      "136/136 [==============================] - 25s 184ms/step - loss: 0.0160 - accuracy: 0.9977 - val_loss: 0.0150 - val_accuracy: 0.9969\n",
      "Epoch 3/5\n",
      "136/136 [==============================] - 25s 185ms/step - loss: 0.0394 - accuracy: 0.9931 - val_loss: 0.0220 - val_accuracy: 0.9959\n",
      "Epoch 4/5\n",
      "136/136 [==============================] - 25s 186ms/step - loss: 0.0124 - accuracy: 0.9971 - val_loss: 0.0261 - val_accuracy: 0.9969\n",
      "Epoch 5/5\n",
      "136/136 [==============================] - 25s 186ms/step - loss: 0.0104 - accuracy: 0.9971 - val_loss: 0.0098 - val_accuracy: 0.9990\n",
      "Epoch 1/5\n",
      "136/136 [==============================] - 25s 185ms/step - loss: 0.0067 - accuracy: 0.9986 - val_loss: 0.0161 - val_accuracy: 0.9990\n",
      "Epoch 2/5\n",
      "136/136 [==============================] - 26s 189ms/step - loss: 0.0210 - accuracy: 0.9962 - val_loss: 0.0144 - val_accuracy: 0.9990\n",
      "Epoch 3/5\n",
      "136/136 [==============================] - 26s 190ms/step - loss: 0.0070 - accuracy: 0.9980 - val_loss: 0.0150 - val_accuracy: 0.9990\n",
      "Epoch 4/5\n",
      "136/136 [==============================] - 26s 192ms/step - loss: 0.0085 - accuracy: 0.9979 - val_loss: 0.0277 - val_accuracy: 0.9948\n",
      "Epoch 5/5\n",
      "136/136 [==============================] - 26s 189ms/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 0.0144 - val_accuracy: 0.9990\n",
      "Epoch 1/5\n",
      "136/136 [==============================] - 26s 189ms/step - loss: 0.0088 - accuracy: 0.9977 - val_loss: 0.0011 - val_accuracy: 0.9990\n",
      "Epoch 2/5\n",
      "136/136 [==============================] - 26s 192ms/step - loss: 0.0105 - accuracy: 0.9970 - val_loss: 7.2630e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "136/136 [==============================] - 26s 190ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 1.9540e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "136/136 [==============================] - 27s 196ms/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 0.0011 - val_accuracy: 0.9990\n",
      "Epoch 5/5\n",
      "136/136 [==============================] - 26s 194ms/step - loss: 0.0040 - accuracy: 0.9985 - val_loss: 0.0010 - val_accuracy: 0.9990\n",
      "Epoch 1/5\n",
      "136/136 [==============================] - 26s 194ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 6.1761e-05 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "136/136 [==============================] - 26s 192ms/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 2.4132e-05 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "136/136 [==============================] - 26s 192ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 7.1579e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "136/136 [==============================] - 26s 193ms/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 1.7841e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "136/136 [==============================] - 26s 195ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 4.3225e-04 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "136/136 [==============================] - 26s 192ms/step - loss: 0.0020 - accuracy: 0.9992 - val_loss: 0.0010 - val_accuracy: 0.9990\n",
      "Epoch 2/5\n",
      "136/136 [==============================] - 26s 191ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 3.0810e-05 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "136/136 [==============================] - 26s 189ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 2.0218e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "136/136 [==============================] - 26s 189ms/step - loss: 5.5354e-04 - accuracy: 0.9997 - val_loss: 8.7995e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "136/136 [==============================] - 26s 189ms/step - loss: 5.3201e-04 - accuracy: 0.9998 - val_loss: 1.7623e-04 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "136/136 [==============================] - 26s 191ms/step - loss: 4.5236e-04 - accuracy: 0.9999 - val_loss: 1.6549e-05 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "136/136 [==============================] - 26s 191ms/step - loss: 2.8860e-04 - accuracy: 1.0000 - val_loss: 1.2615e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "136/136 [==============================] - 26s 192ms/step - loss: 2.1705e-04 - accuracy: 1.0000 - val_loss: 1.2470e-05 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "136/136 [==============================] - 26s 192ms/step - loss: 2.1194e-04 - accuracy: 1.0000 - val_loss: 1.0292e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "136/136 [==============================] - 26s 192ms/step - loss: 1.9585e-04 - accuracy: 1.0000 - val_loss: 2.2906e-05 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "136/136 [==============================] - 26s 192ms/step - loss: 1.4891e-04 - accuracy: 1.0000 - val_loss: 3.2221e-04 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "136/136 [==============================] - 26s 191ms/step - loss: 1.1544e-04 - accuracy: 1.0000 - val_loss: 2.7514e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "136/136 [==============================] - 26s 188ms/step - loss: 1.2753e-04 - accuracy: 1.0000 - val_loss: 3.5354e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "136/136 [==============================] - 26s 191ms/step - loss: 1.1662e-04 - accuracy: 1.0000 - val_loss: 3.0372e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "136/136 [==============================] - 26s 192ms/step - loss: 1.0092e-04 - accuracy: 1.0000 - val_loss: 3.0514e-04 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "136/136 [==============================] - 27s 197ms/step - loss: 1.3093e-04 - accuracy: 1.0000 - val_loss: 1.4927e-04 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "136/136 [==============================] - 26s 193ms/step - loss: 1.0699e-04 - accuracy: 1.0000 - val_loss: 1.2359e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "136/136 [==============================] - 26s 192ms/step - loss: 1.1931e-04 - accuracy: 1.0000 - val_loss: 1.7360e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "136/136 [==============================] - 26s 190ms/step - loss: 9.7252e-05 - accuracy: 1.0000 - val_loss: 1.3311e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "136/136 [==============================] - 26s 193ms/step - loss: 1.1593e-04 - accuracy: 1.0000 - val_loss: 1.2861e-04 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "136/136 [==============================] - 26s 192ms/step - loss: 1.2332e-04 - accuracy: 1.0000 - val_loss: 1.2491e-04 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "136/136 [==============================] - 26s 192ms/step - loss: 1.2010e-04 - accuracy: 1.0000 - val_loss: 1.6525e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "136/136 [==============================] - 26s 193ms/step - loss: 8.6243e-05 - accuracy: 1.0000 - val_loss: 2.0820e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "136/136 [==============================] - 26s 188ms/step - loss: 1.0648e-04 - accuracy: 1.0000 - val_loss: 1.1744e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "136/136 [==============================] - 26s 194ms/step - loss: 7.9715e-05 - accuracy: 1.0000 - val_loss: 2.3055e-04 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "136/136 [==============================] - 26s 189ms/step - loss: 9.6288e-05 - accuracy: 1.0000 - val_loss: 1.2631e-04 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "136/136 [==============================] - 26s 191ms/step - loss: 8.4886e-05 - accuracy: 1.0000 - val_loss: 6.9068e-05 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "136/136 [==============================] - 26s 194ms/step - loss: 9.1437e-05 - accuracy: 1.0000 - val_loss: 1.0776e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "136/136 [==============================] - 26s 193ms/step - loss: 9.2393e-05 - accuracy: 1.0000 - val_loss: 1.3759e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "136/136 [==============================] - 26s 193ms/step - loss: 8.4060e-05 - accuracy: 1.0000 - val_loss: 8.0762e-05 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(10)\n",
    "\n",
    "X = np.array([i[0] for i in DATA_SET]).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
    "Y = np.array([i[1] for i in DATA_SET])\n",
    "fold = 0\n",
    "\n",
    "for train, test in kf.split(DATA_SET):\n",
    "    fold += 1\n",
    "    x_train = X[train]\n",
    "    y_train = Y[train]\n",
    "    x_test = X[test]\n",
    "    y_test = Y[test]\n",
    "\n",
    "    model.fit(x_train, y_train, validation_data=(x_test, y_test), verbose = 1, epochs= 5, batch_size=64)\n",
    "    Model_name = 'movie-model-fold' + str(fold) + '.h5'\n",
    "    weights_name = 'movie-weight-fold' + str(fold) + '.h5'\n",
    "    model.save(Model_name, overwrite = True, include_optimizer = True)\n",
    "    model.save_weights(weights_name, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}